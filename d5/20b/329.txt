D5P329-200704
7.4，经历大致两周的颓废状态（说是颓废，其实我的厨艺有很大长进lol，也看了不少时事政治如《骁话一下》），我突然恢复了学习动力，开始学NLP、刷leetcode。
7.6整了一下Stanford的入学手续，翻以前的体检文件发现自己是AB+型血…之后某政策出台，留学生圈子又炸锅了，在国内的上不了课，在美国的要被遣返。看到美帝这么作死，看到留学生群体对美国的印象暴跌，看到有良知的美国人集体表达对政府的不满和羞耻，我心里反而感觉挺开心的…
7.8凌晨做出了LC 315，感觉很爽，这题我思考的时候猜对了最佳时间复杂度、排除了一些常见的方法，但还是想不出来，后来看答案以后发现了新的解题方法。如果一道题看了答案，原则上我需要间隔至少半天，然后再独立实现一遍算法，确保自己真正理解。
7.8~7.9连做了4道LC Hard。哎，最近刷题来劲了，NLP也没怎么学，我学习真是太随性了，对什么来了兴致就学啥。话说最近我刷微信和pyq的频率空前地高，感觉是时候控制一下自己了，不过狂刷手机可以让自己不感觉孤独就是了。
回到NLP的学习上。3月探索AI的那个时代，我从知乎上关注了NLP大神、26岁的百度程序媛夕小瑶，以及她的微信公号“夕小瑶的卖萌屋”。她写的文章我还在看，那篇用马尔科夫链和她恋爱的帖子把我看得乐死了额哈哈。
7.11看完了S&LP第2章，了解到很多NLP最常用到的方法并非基于NN，比如regex（regex这个技能和我最近在做的日记分析，包括词数统计等工作，非常相关），还有在拼写改正等功能里需要用到的LC 74（Edit Distance）问题，用的是DP。
这似乎应证了我4月在知乎上看到的印象深刻的一句话，“算法工程师，先是工程师，再是算法工程师…所以Leetcode走天下”。从某个角度讲，LC上的字符串问题，也可以算是NLP的范畴啊。
最近除了CS 224n以外，我看的最多的便是《数学之美》了，半年前495给我推荐它的时候，我不曾想到它会给我带来如此巨大的启蒙作用。
这本书和我看过其他所有教材不同的地方在于，他是从工业界解决实际问题的角度来讲概念，比如搜索引擎算法的原理以及遇到的“bad case”问题，让我能体会到编程技能的实际用处。书中还涉及了很多CS科学家的成长轨迹和读博经历。
书中的一个核心观点是，NLP应该用信息学而不是语言学的视角去分析，解决一切问题的核心都是“利用信息消除不确定性”。一个词可以以二维编码的形式储存，也可以以向量的形式表达它的意义。
《数学之美》是2012年出版的，而据CS 224n说，2013年word2vec的出现改变了整个NLP世界；现在似乎NLP的一切似乎都是“炼丹”驱动的，所以我还不知道我学的这些“传统方法”和“内功”、“核心”有多少用，但至少夕小瑶曾说过她后悔没有系统地学过信息论…
但夕小瑶的面经贴里，考的内容基本上都是模型架构、训练方法、评价体系。WTF，所以我现在学的东西有用吗？？上次面CV创业公司的日记无数次在我脑中回荡（D5P311-200415）：
<blockquote>
“最后对我得出的结论是我的MASI项目就光调参了，没有深入了解常用网络结构的原理。我无奈地表示我比较擅长梯度下降、反向传播的理论，面试官说这些都用不到的，我醉了…”
</blockquote>
看着NLP大神讲起各种模型，我感觉像看天书一样（就像实习时听组会的时候…），顿时慌的一批，后来看到一位腾讯小哥的面经，考到了n元模型、文本相似性、HMM、维特比，啊这不都是我刚学的吗！这才平静下来…
