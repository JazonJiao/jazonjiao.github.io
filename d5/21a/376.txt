D5P376-210216
2`2.13晚21:00 ~ 0:30和966写224n的Proposal（大部分是我写的）。996刚在主机里嵌了个8GB的GPU，用来跑她那个医学图像lab的模型，工作效率大大提升。

1`2.15继续一起写proposal（共2小时）时，966的猫把她电脑电源拔断了。761的3人组做Robust，说office hour上TA告诉她们，3人组最好做Robust，“搞我们心态”。770带着745做他NLP Group的project，“大哥说做啥就做啥”。
1`224n的第9、10节课是John Hewitt（我们的Head TA）上的，讲得太棒了！以前看paper看不懂的Transformer和BERT，他讲得真是深入浅出，我很快就明白了。
3`2.14在783的clubhouse局上，761提到她和bf办了个domestic partner的证，办很多事都方便多了；和同性朋友也可以办。局上认识了一位MCDS同学（868），在上11797（CMU竟然有一门专门的NLP QA课），说他会看每年的224n海报。他还说MCDS美本的十几位同学有一半都待在本科学校上网课。
3`2.14下午，778回来了；他还是没找到实习，惊了。2.15，473和我吐槽她PhD申请结果很糟糕；2.25她录了UIUC。
1`2.17写224n作业5时，train没问题，eval时老出bug，搞了好久竟然是因为我torch.save() 保存的是trainer，而不是model.state_dict()，神tm白训练了2个多小时…真服了我自己。
1`Q2g的tensor shape一直不对又搞了好久，然后迷迷糊糊地可以train了，但train loss却到了0.03（正常应该接近0.55），output出来都是乱码，我苦思冥想也debug不出来，最后竟然是view和transpose的问题。这次作业写了25+小时…
1`作业5是今年新出的（这也意味着很多题目说的都不太清楚，TA们还写了篇很长的clarification），第一部分探索multi-head attention，第二部分探索pretraining，都是非常新的概念，不禁让人感叹NLP发展之快。实际上，我暑假从《数学之美》上学的很多NLP概念都“过时”了…
1`2.19作业5已经due了，但2.20，224n的OH排起了近50人的长队（学生总数475），太可怕了。966说John大神严重高估了同学们的能力，对此很愧疚；他本来甚至想Encoder、Decoder也让我们自己写，被其他TA制止了。
3`2.17、18，774、761分别过了23岁生日。2.19晚上聚餐，聚餐期间桌子半边的女生（763、776、799）疯狂聊各种电视剧、明星；桌子另半边的我、774、770、564听着一脸懵逼。
饭后打七鬼、玩真心话，玩着玩着就直接变成776提问、大家挨个回答了。她问了（1）怎么走出第一次失恋的；（2）母亲教会最重要的事情是什么。感谢776，这波让大家对彼此的成长的轨迹都有了深刻得多的了解。
