D5P287-200127
1`24号我准备开始我的研究项目，467学长帮了我很多忙。27号，我正式重启了自己的科研之路！下午，498和我见面，继续介绍我们的项目：他用了一个别人写好的neural net，调了一周的参，基本上都搞好了，我只要验证一下有没有bug就行（这么简单的项目还能写一篇paper出来？…）后面可能用docker把软件打包。回MASI以后我把epoch设成70、batch_size设成8，开始9小时长的训练。
1`由于batch_size小，训练不需要很多内存，主机的11 GB就够了。467说如果放在ACCRE上训练，指不定ACCRE挂了你的结果就没了，而且ACCRE每两周就会挂一次？这让我想起去年暑假每次读本来21 GB的数据，到pandas里就会占用近70 GB的内存，导致Work Lab的大电脑也经常挂掉…
1`28号我跟686继续去MASI，至此已经在lab呆了7小时。先是电脑死机，于是467确认了一下其他人有没有在用我机子的内存跑东西，我才重启了电脑。迅速跑完testing之后，epoch 60的网络loss竟比epoch 70的略低，但算主动脉分割的Dice coefficient（我们使用的准确度验证公式）的时候60比70稍差（88%比89%）。
1`498说现在用的网络（DeepLabV3）是general-purpose 图像分割里最好的算法，不过对于主动脉分割这个细方向，有更好的算法。MASI主要还是发医学图像处理方向的paper（Dr. Landman是SPIE的chair），CS、ML发的比较少，medical和CS侧重点还是有区别，我们也没有专业搞CV的lab的计算资源。
1`按现在我们的算法，训练时每个batch是乱序的8个png，图像的第三维度信息是丢失的（本应该是100张从上往下的横截面图片）。这种纯二维算法导致了我们的数据前处理、后处理的一些麻烦，也限制了batch size和/或图像的清晰度。我问有没有更“三维”的图像分割算法（比如用于视频的），可以考虑进图像的连续性，498说这是现在不少人在做的方向（比如2.5维训练）。
2`后来我overhear了498和497的对话，大概是讲遇到老板布置却又不想做的项目怎么办：先汇报进度给老板吃定心丸，再提别的。他还评价467有时会被engineering side拖进度：downsample图像总是出bug，一搞就是好几天，阻碍了新想法的提出…
1`28晚上，当我学习CNN的原理、思考CV问题的本质、探索AI究竟可以做什么，我对AI的热情重燃。距离我开始接触AI已经过去了两年时间，我才终于得以在课外真正实践这些知识！很多东西都是YouTube上看到的或者18年暑假在Brilliant上学的，现在终于派上用场！
2`我多希望我去年此时就加入MASI啊，当时我的能力完全能胜任现在的我能做的事情！这一年的迷茫倒是导致了我新年前三周对各行各业的探索，差点因为495而改行金融/商科（我之前还打算着2月开始强度networking一波），最后也许会回到AI吧…
1`29号，498和我说医生给了他7个新的CT图集，我需要在上面标注主动脉，然后跑算法验证。于是我下载了相应的软件，467一如既往地热心，帮了我很多，我不熟Linux，经常遇到啥问题的时候，他打几句linux command就解决了。
1`498说去年暑假有人需要在100个CT图集上标肝脏（每个图集会有约100张切片），非常费时费力。好在主动脉很好分辨，轮廓也很简单。31号，在整好各种bug以后，我开始相对枯燥的标注任务。
1`498还提了两个可能可以继续探究的问题，都和training data的class imbalance有关。有的器官（如肾上腺）很小，由于现在使用的loss function是cross entropy或dice coefficient，网络训练的时候会轻视这个class的表现，导致其准确度只有约40%。（用中文写这些ML技术性的东西好蛋疼…）
1`另外，有的重症病人的CT图像和正常人的有不少差别，如果把它们作为training数据则会干扰网络的训练，但不这样的话网络在这些outliers上则不会表现得很好。
1`2月3号，我拿着新的7个数据，开始尝试跑之前训练好的网络来做分割，由于这个数据和以前的有点不一样（比如没有对照组、没有ground truth），我需要自己研究、修改498的代码，现在还有不少debug要做。4号跑完了7个新数据的testing、标完了数据2、3的主动脉。
1`这几天回顾着3b1b、carykh、Welch Labs的视频、Michael Nielson的书，我一直在边看边想，上面这两个问题不一定用神经网络，或许可以用更analytical（偏算法）的方法做。ML里有无数种方法，为什么我们lab现在在用这些方法而不是其他的呢？
1`深度学习是一个十分玄学的东西，什么东西都可以用它来做，有时会成功有时会失败，成功或失败的原因却很难知道。467说一般他们测试一个算法的好坏，会用“ResNet”作为baseline。
